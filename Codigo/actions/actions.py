
from random import randint
from typing import Any, Text, Dict, List
from rasa_sdk import Action, Tracker
from rasa_sdk.executor import CollectingDispatcher
from rasa_sdk.events import SlotSet, FollowupAction, ConversationPaused
from transformers import TFGPT2LMHeadModel, GPT2Tokenizer, AutoTokenizer, AutoModel, TFAutoModel, pipeline

QUESTIONS = [
    "¬øCon qu√© frecuencia tiene poco inter√©s o placer en realizar cosas?",
    "En las dos √∫ltimas semanas, ¬øcon qu√© frecuencia se ha sentido deca√≠do/a, deprimido/a o sin esperanzas?",
    "¬øQu√© dificultad ha tenido para conciliar el sue√±o o, en caso opuesto, en levantarse de la cama?",
    "En las dos √∫ltimas semanas, ¬øcon qu√© frecuencia ha experimentado cansancio o falta de energ√≠a?",
    "¬øCon qu√© frecuencia cree que ha sentido falta o exceso de apetito?",
    "En las dos √∫ltimas semanas, ¬øcon qu√© recurrencia se ha sentido mal consigo mismo/a, "
    "que es un fracaso o qu√© le ha fallado a sus seres queridos?",
    "¬øCon cu√°nta dificultad se ha enfrentado para centrarse en actividades, como leer o ver la televisi√≥n?",
    "¬øCon qu√© abundancia cree que se ha movido o hablado tan despacio/r√°pido que otras personas "
    "lo puedan haber notado?",
    "En las dos √∫ltimas semanas, ¬øcon qu√© frecuencia ha tenido pensamientos que impliquen autolesi√≥n o que "
    "impliquen que estar√≠a mejor muerto/a?",
]


class ActionAskQuestion(Action):

    def name(self) -> Text:
        return "action_ask_question"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[Text, Any]) -> List[Dict[Text, Any]]:
        current_question = tracker.get_slot('question_id')
        if current_question == len(QUESTIONS):
            return [FollowupAction("action_end_conversation")]
        dispatcher.utter_message(text=f"**Pregunta {current_question + 1} de {len(QUESTIONS)}** \n --- \n" +
                                      QUESTIONS[current_question])
        nlp = pipeline('question-answering', model='mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es',
            tokenizer=('mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es', {"use_fast": False}))
        dispatcher.utter_message(text=nlp({'question': QUESTIONS[current_question],'context': 'Diego esta sufriendo de estr√©s por la separaci√≥n con su esposa '})['answer'])
        return [SlotSet('question_id', current_question + 1)]

class ActionStartQuestions(Action):

    def name(self) -> Text:
        return "action_start_questions"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[Text, Any]) -> List[Dict[Text, Any]]:
        dispatcher.utter_message(text="Muy bien, ¬°comencemos!")
        return [SlotSet('state', 'questions')]


class ActionEndConversation(Action):

    def name(self) -> Text:
        return "action_end_conversation"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[Text, Any]) -> List[Dict[Text, Any]]:
        is_asking = tracker.get_slot('state') == 'questions'
        if is_asking:
            dispatcher.utter_message(text="Gracias por responder a mis preguntas üòÅ")
        else:
            dispatcher.utter_message(text="Est√° bien. ¬°Espero hablar contigo en otro momento!")
           

        return [ConversationPaused()]

#class  example(Action):

#    def name(self) -> Text:#
#       return "example"
  
#    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: Dict[Text, Any]) -> List[Dict[Text, Any]]:
#        nlp = pipeline('question-answering', model='mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es', 
#            tokenizer=('mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es', {"use_fast": False}))

#        dispatcher.utter_message(text=nlp({QUESTIONS[0]: '¬øPara qu√© lenguaje est√° trabajando?', 'context': 'Manuel Romero est√° colaborando activamente con huggingface/transformers ' +
 #                   'para traer el poder de las √∫ltimas t√©cnicas de procesamiento de lenguaje natural al idioma espa√±ol'}))
 #       return [SlotSet('state','text-kiut')]

        #nlp1 = pipeline( 'question-answering', model='mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es', 
        #    tokenizer=('mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es',{"use_fast": False}))
       # return  [SlotSet(nlp1({'question': 'question','context': 'question'}))]
